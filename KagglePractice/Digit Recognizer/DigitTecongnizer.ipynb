{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "print(train.shape) #(42000, 785)\n",
    "print(test.shape) #(28000, 784)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = train.drop('label', axis=1)\n",
    "Y_train = train['label']\n",
    "print(X_train.shape, Y_train.shape)\n",
    "g = sns.countplot(Y_train)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isnull().any().sum())\n",
    "print(test.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confit\n",
    "num_classes = 10\n",
    "random_seed = 2\n",
    "epochs = 30 \n",
    "batch_size = 56\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'kevin.h5py'\n",
    "\n",
    "#第一次執行忽略下列兩行\n",
    "# model_path = os.path.join(save_dir, model_name)\n",
    "# model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28, 1) (8400, 28, 28, 1) (33600, 10)\n"
     ]
    }
   ],
   "source": [
    "#Normalize\n",
    "X_train = X_train/255\n",
    "test = test/255\n",
    "\n",
    "#Reshape\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "#one hat encoding\n",
    "Y_train = to_categorical(Y_train, num_classes = num_classes)\n",
    "\n",
    "#split train,valication set\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "print(X_train.shape, X_val.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[18][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model\n",
    "# [conv2d *2 + maxpoll2d + dropout]*2 + Flatten + Dense + dropout + out\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n",
    "#                  activation ='relu', input_shape = (28,28,1)))\n",
    "# model.add(Conv2D(filters = 16, kernel_size=(3,3), padding='Same', \n",
    "#                  activation = 'relu', input_shape = (28,28,1)))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(1,1)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3,3), padding='Same', \n",
    "                 activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(1,1)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3,3), padding='Same', \n",
    "                 activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(1,1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',  #val_loss\n",
    "                                            factor=0.5, \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            mode='auto', \n",
    "                                            epsilon=0.0001, \n",
    "                                            cooldown=0, \n",
    "                                            min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         zoom_range = 0.2, # Randomly zoom image \n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False)  # randomly flip images\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 417s - loss: 0.4798 - acc: 0.8474 - val_loss: 0.0806 - val_acc: 0.9760\n",
      "Epoch 2/30\n",
      " - 415s - loss: 0.1984 - acc: 0.9417 - val_loss: 0.0593 - val_acc: 0.9820\n",
      "Epoch 3/30\n",
      " - 415s - loss: 0.1566 - acc: 0.9553 - val_loss: 0.0536 - val_acc: 0.9838\n",
      "Epoch 4/30\n",
      " - 416s - loss: 0.1369 - acc: 0.9602 - val_loss: 0.0514 - val_acc: 0.9848\n",
      "Epoch 5/30\n",
      " - 436s - loss: 0.1196 - acc: 0.9641 - val_loss: 0.0448 - val_acc: 0.9864\n",
      "Epoch 6/30\n",
      " - 472s - loss: 0.1109 - acc: 0.9673 - val_loss: 0.0445 - val_acc: 0.9869\n",
      "Epoch 7/30\n",
      " - 435s - loss: 0.1112 - acc: 0.9665 - val_loss: 0.0451 - val_acc: 0.9880\n",
      "Epoch 8/30\n",
      " - 436s - loss: 0.1030 - acc: 0.9701 - val_loss: 0.0426 - val_acc: 0.9879\n",
      "Epoch 9/30\n",
      " - 437s - loss: 0.0974 - acc: 0.9710 - val_loss: 0.0423 - val_acc: 0.9875\n",
      "Epoch 10/30\n",
      " - 436s - loss: 0.0979 - acc: 0.9715 - val_loss: 0.0354 - val_acc: 0.9894\n",
      "Epoch 11/30\n",
      " - 436s - loss: 0.0877 - acc: 0.9740 - val_loss: 0.0317 - val_acc: 0.9905\n",
      "Epoch 12/30\n",
      " - 434s - loss: 0.0927 - acc: 0.9745 - val_loss: 0.0374 - val_acc: 0.9888\n",
      "Epoch 13/30\n",
      " - 436s - loss: 0.0874 - acc: 0.9746 - val_loss: 0.0319 - val_acc: 0.9904\n",
      "Epoch 14/30\n",
      " - 415s - loss: 0.0862 - acc: 0.9743 - val_loss: 0.0326 - val_acc: 0.9910\n",
      "Epoch 15/30\n",
      " - 417s - loss: 0.0814 - acc: 0.9764 - val_loss: 0.0303 - val_acc: 0.9912\n",
      "Epoch 16/30\n",
      " - 415s - loss: 0.0855 - acc: 0.9766 - val_loss: 0.0355 - val_acc: 0.9895\n",
      "Epoch 17/30\n",
      " - 415s - loss: 0.0777 - acc: 0.9767 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 18/30\n",
      " - 415s - loss: 0.0793 - acc: 0.9774 - val_loss: 0.0342 - val_acc: 0.9907\n",
      "Epoch 19/30\n",
      " - 413s - loss: 0.0801 - acc: 0.9777 - val_loss: 0.0383 - val_acc: 0.9900\n",
      "Epoch 20/30\n",
      " - 416s - loss: 0.0791 - acc: 0.9777 - val_loss: 0.0341 - val_acc: 0.9892\n",
      "Epoch 21/30\n",
      " - 422s - loss: 0.0784 - acc: 0.9772 - val_loss: 0.0369 - val_acc: 0.9900\n",
      "Epoch 22/30\n",
      " - 450s - loss: 0.0756 - acc: 0.9785 - val_loss: 0.0345 - val_acc: 0.9898\n",
      "Epoch 23/30\n",
      " - 443s - loss: 0.0771 - acc: 0.9775 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 24/30\n",
      " - 417s - loss: 0.0606 - acc: 0.9825 - val_loss: 0.0272 - val_acc: 0.9931\n",
      "Epoch 25/30\n",
      " - 417s - loss: 0.0563 - acc: 0.9839 - val_loss: 0.0264 - val_acc: 0.9915\n",
      "Epoch 26/30\n",
      " - 413s - loss: 0.0551 - acc: 0.9847 - val_loss: 0.0258 - val_acc: 0.9926\n",
      "Epoch 27/30\n",
      " - 413s - loss: 0.0530 - acc: 0.9849 - val_loss: 0.0325 - val_acc: 0.9911\n",
      "Epoch 28/30\n",
      " - 414s - loss: 0.0558 - acc: 0.9843 - val_loss: 0.0276 - val_acc: 0.9937\n",
      "Epoch 29/30\n",
      " - 417s - loss: 0.0494 - acc: 0.9859 - val_loss: 0.0301 - val_acc: 0.9932\n",
      "Epoch 30/30\n",
      " - 418s - loss: 0.0528 - acc: 0.9856 - val_loss: 0.0264 - val_acc: 0.9930\n",
      "Loading trained model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e69d356a4244>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# loading our save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading trained model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Score trained model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])\n",
    "\n",
    "\n",
    "# Plot the loss and accuracy curves for training and validation \n",
    "# fig, ax = plt.subplots(2,1)\n",
    "# ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "# ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "# legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "# ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "# ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "# legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-19cf606e395a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loading our save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading trained model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Score trained model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "#第一次執行忽略下列兩行\n",
    "# model_path = os.path.join(save_dir, model_name)\n",
    "# model = load_model(model_path)\n",
    "\n",
    "# loading our save model\n",
    "print(\"Loading trained model\")\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(X_val, Y_val, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "\n",
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"digit.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
